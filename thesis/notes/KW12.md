### Set up a training pipeline
#### Task: Classification on BACE Dataset
As a downstream task that serves as a benchmark comparison between the performance of ECFP bit vectors and my GNNs I will use the BACE dataset from MoleculeNet. This will be a binary classification task in which I the classifier tries to predict a label 1 or 0 for a given molecule. For this I will have to import the dataset, remove unwanted features and split it into a train and a test set (80%/20%)
#### Example 1: ECFP2 with an MLP classifier
I will create ECFP2 bit vectors from the smiles strings of the training set and feed them into a multi-layer-perceptron. Then I will test its acuraccy against the ECFP2 bit vectors of the test set.

#### Example 2: Single layer GIN with an MLP classifier
I will create graph representations of the molecules using the `from_smiles` function implemented in pytorch_geometric. Then I will feed them into a single layer GIN that uses the sum aggregation to aggregate information from neighbouring atoms. These graph embeddings will be fed into a multi layer perceptron. The performance of the MLP will be validated with the graph represenations of the test set.

### Review Expos√©
- Comparison between ECFP and neural fingerprint methods
	- 3 important differences (hashing, duplicate removal, bit array)
- Section General idea and architecture
- Challenges to consider:
	- Duplicate removal
	- hashing
	- fixed size fingerprint with concatenation
- Schedule